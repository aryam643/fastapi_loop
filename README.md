#  Store Monitoring System

A **comprehensive backend API system** for monitoring restaurant store uptime and generating detailed reports.
Built with **FastAPI**, **SQLAlchemy**, and advanced **business hours logic**.

---

## ğŸ“Œ Table of Contents

* [Architecture](#-system-architecture)
* [Data Flow](#-data-flow-diagram)
* [API Sequences](#-api-sequences)
* [Features](#-features)
* [Project Structure](#-project-structure)
* [API Endpoints](#-api-endpoints)
* [Setup Instructions](#-setup-instructions)
* [Testing](#-testing)
* [Key Features Explained](#-key-features-explained)
* [Performance Considerations](#-performance-considerations)
* [Error Handling](#-error-handling)
* [Sample Output](#-sample-output)
* [Future Improvements](#-improvements-for-production)

---

## ğŸ— System Architecture

![System Flow](https://github.com/user-attachments/assets/f0469a4f-46a1-4557-ba09-f37fda7b2dba)

---

## ğŸ”„ Data Flow Diagram

![Data Flow](https://github.com/user-attachments/assets/4bfe5208-1881-4e60-83d5-a16daea5e5a7)

---

## ğŸ“¡ API Sequences

![API Sequence](https://github.com/user-attachments/assets/f32bec5d-d4c1-49d9-8d9d-92c88885ac82)

---

## âœ¨ Features

* âš¡ **Async Report Generation** â€“ trigger reports & poll for completion
* ğŸ•’ **Business Hours Support** â€“ including overnight operations
* ğŸŒ **Timezone Conversion** â€“ with DST handling
* ğŸ“Š **Data Interpolation** â€“ extrapolates uptime/downtime from sparse polling data
* ğŸ“‘ **CSV Export** â€“ validated reports with statistics & formatting
* ğŸ›  **RESTful API** â€“ clean FastAPI endpoints with robust error handling

---

## ğŸ“‚ Project Structure

```bash
store-monitoring/
â”œâ”€â”€ main.py                    # FastAPI app & routes
â”œâ”€â”€ models.py                  # SQLAlchemy models
â”œâ”€â”€ database.py                # DB config & session
â”œâ”€â”€ data_processor.py          # Data import logic
â”œâ”€â”€ report_generator.py        # Core reporting engine
â”œâ”€â”€ report_service.py          # Service layer
â”œâ”€â”€ business_hours_utils.py    # Business hours logic
â”œâ”€â”€ csv_export_utils.py        # CSV utilities
â”œâ”€â”€ data_import_script.py      # Data ingestion script
â”œâ”€â”€ run_server.py              # App entrypoint
â”œâ”€â”€ tests/                     # Unit & API tests
â”‚   â”œâ”€â”€ test_api.py
â”‚   â””â”€â”€ test_business_hours.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ start_server.sh
â”œâ”€â”€ data/                      # CSV input files
â””â”€â”€ reports/                   # Generated CSV reports
```

---

## ğŸ”Œ API Endpoints

### 1ï¸âƒ£ Trigger Report

```http
POST /trigger_report
```

**Response:**

```json
{ "report_id": "uuid-string" }
```

**Example:**

```bash
curl -X POST http://localhost:8000/trigger_report
```

---

### 2ï¸âƒ£ Get Report Status / Download

```http
GET /get_report/{report_id}
```

**Running Response:**

```json
{ "status": "Running", "created_at": "timestamp" }
```

**Completed Response:** Downloads CSV

```csv
store_id,uptime_last_hour,uptime_last_day,uptime_last_week,downtime_last_hour,downtime_last_day,downtime_last_week
```

---

### 3ï¸âƒ£ Health Check

```http
GET /health
```

---

## âš™ï¸ Setup Instructions

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Prepare Data

Place CSV files in the `data/` folder:

* `store_status.csv`
* `business_hours.csv`
* `store_timezones.csv`

### 3. Import Data

```bash
python data_import_script.py
```

### 4. Start Server

```bash
python run_server.py
# OR
./start_server.sh
```

API available at ğŸ‘‰ `http://localhost:8000`

---

## ğŸ§ª Testing

```bash
# Run API tests
pytest tests/test_api.py

# Test business hours logic
pytest tests/test_business_hours.py

# Generate sample reports
python generate_sample_report.py
```

---

## ğŸ” Key Features Explained

### ğŸ•’ Business Hours Logic

* Supports **normal** (9 AM â€“ 5 PM) and **overnight** (10 PM â€“ 6 AM) schedules
* Handles **timezone conversion + DST**
* Defaults: **24/7** if hours missing, **America/Chicago** if timezone missing

### ğŸ“Š Report Algorithm

1. Collects store status data (last hour/day/week)
2. Converts UTC â†’ local store time
3. Filters by business hours
4. Interpolates uptime/downtime
5. Aggregates by time period
6. Exports validated CSV

---

## ğŸ“‰ Sample Output

```csv
store_id,uptime_last_hour,uptime_last_day,uptime_last_week,downtime_last_hour,downtime_last_day,downtime_last_week
store_0001,58.50,22.75,165.25,1.50,1.25,2.75
store_0002,45.25,18.50,142.00,14.75,5.50,26.00
```

---

## ğŸš€ Improvements for Production

* **Database** â†’ PostgreSQL + indexing + partitioning
* **Caching** â†’ Redis, query result caching
* **Scalability** â†’ Celery + Kubernetes + microservices
* **Monitoring** â†’ Prometheus, OpenTelemetry, structured logs
* **Security** â†’ JWT, RBAC, rate limiting, encryption
* **Advanced Features** â†’ Scheduling, custom ranges, visual dashboards
* **DevOps** â†’ CI/CD, API versioning, feature flags


